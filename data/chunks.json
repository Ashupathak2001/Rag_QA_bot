["Title -Data Science Researcher-Intern Location: Currently Remote Type of Position-Internship About Accredian: Accredian is a fast growing edtech company that was started in 2018 by ISB MBAs. The company has so far served 18,000+ professionals working in almost 3000 companies. Accredian arms working professionals with next generation skills like Data Science, Digital Transformation, Business Management, Product management in partnership with top tier institutions like IITs, IIMs, XLRI and provides them a transformative learning experience to help them move up in their careers. The Role: We are looking for Data Science Researchers to help us build a great platform where individuals", "can learn and upskill in Data Science with ease. Your ultimate goal will be to improve our outreach, student experience, and developing content that can be leveraged in regular sessions. Your responsibilities will include: \u25cf Write high-quality articles on next-generation technologies like Data Science, Machine Learning & AI - drive traffic to the website, build/engage an audience, and build brand authority. \u25cf Design, curate and publish the highest quality experiential content for Data Science & AI audiences. This includes creating experiences, text, videos and interactive activities. \u25cf Excellent communication skills to talk business in terms of data science, machine learning,", "and AI. \u25cf Defining and leading our strategy in making data science easy and accessible to all. \u25cf Develop electronic and web communication to support company publications and information dissemination. \u25cf Research and collect information for books, guides, and webinars full of industry insights. \u25cf Create web content including research reports, blog articles & build content assets that will drive conversions. \u25cf Help develop and execute content planning in line with business objectives and priorities. \u25cf Work with the team to create stories with the data using visualization tools/methods. \u25cf Maintains proficiency within the data science domain by keeping up", "with technology and trend shifts. \u25cf Be flexible to upgrade your knowledge in a short time frame. \u25cf Have a startup attitude - \u2018Getting things done\u2019.", "What\nyou\u2019ll\nneed?\nTechnical\nskills:\nHigh-level\nunderstanding\nof\nPython\nand\nR\nprogramming\nlanguages.\n\u25cf\nFlair\nfor\nwriting\n&\ncreating\nexceptional\ncontent. \n\u25cf\nAbility\nto\nclearly\narticulate\n&\nstructure\nideas\nin\narticles,\nresearch\nreports\n&\nblogs.\n\u25cf\nAbility\nto\ncreate\nbasic\nmodels\nto\npull\ninsights\nfrom\ndata.\nEducation\n&\nExperience\n\u25cf\nBachelor's\nor\nMaster's\ndegree\nin\nMathematics,\nEconomics,\nPhysics,\nComputer\nScience, \nor\nequivalent.\n\u25cf\n0-1\nyear\nexperience", "Title -Data Science Researcher-Intern Location: Currently Remote Type of Position-Internship About Accredian: Accredian is a fast growing edtech company that was started in 2018 by ISB MBAs. The company has so far served 18,000+ professionals working in almost 3000 companies. Accredian arms working professionals with next generation skills like Data Science, Digital Transformation, Business Management, Product management in partnership with top tier institutions like IITs, IIMs, XLRI and provides them a transformative learning experience to help them move up in their careers. The Role: We are looking for Data Science Researchers to help us build a great platform where individuals", "can learn and upskill in Data Science with ease. Your ultimate goal will be to improve our outreach, student experience, and developing content that can be leveraged in regular sessions. Your responsibilities will include: \u25cf Write high-quality articles on next-generation technologies like Data Science, Machine Learning & AI - drive traffic to the website, build/engage an audience, and build brand authority. \u25cf Design, curate and publish the highest quality experiential content for Data Science & AI audiences. This includes creating experiences, text, videos and interactive activities. \u25cf Excellent communication skills to talk business in terms of data science, machine learning,", "and AI. \u25cf Defining and leading our strategy in making data science easy and accessible to all. \u25cf Develop electronic and web communication to support company publications and information dissemination. \u25cf Research and collect information for books, guides, and webinars full of industry insights. \u25cf Create web content including research reports, blog articles & build content assets that will drive conversions. \u25cf Help develop and execute content planning in line with business objectives and priorities. \u25cf Work with the team to create stories with the data using visualization tools/methods. \u25cf Maintains proficiency within the data science domain by keeping up", "with technology and trend shifts. \u25cf Be flexible to upgrade your knowledge in a short time frame. \u25cf Have a startup attitude - \u2018Getting things done\u2019.", "What\nyou\u2019ll\nneed?\nTechnical\nskills:\nHigh-level\nunderstanding\nof\nPython\nand\nR\nprogramming\nlanguages.\n\u25cf\nFlair\nfor\nwriting\n&\ncreating\nexceptional\ncontent. \n\u25cf\nAbility\nto\nclearly\narticulate\n&\nstructure\nideas\nin\narticles,\nresearch\nreports\n&\nblogs.\n\u25cf\nAbility\nto\ncreate\nbasic\nmodels\nto\npull\ninsights\nfrom\ndata.\nEducation\n&\nExperience\n\u25cf\nBachelor's\nor\nMaster's\ndegree\nin\nMathematics,\nEconomics,\nPhysics,\nComputer\nScience, \nor\nequivalent.\n\u25cf\n0-1\nyear\nexperience", "Momenta - Audio Deepfake Detection Take -Home Assessment Welcome! Thank you for your interest in joining the Momenta team! This take -home assessment is designed to evaluate your approach to researching, implementing, and documenting audio deepfake detection solutions. We value your time and have structured this assessmen t to be completed within approximately 3 -5 hours. Assessment Overview Audio deepfakes pose an emerging threat to digital trust. At Momenta, we're developing robust detection systems to identify manipulated audio content across various contexts. Our interview process strays from whiteboard puzzles or DSA questions - we fundam entally believe in testing for", "skills that we expect will be needed. Your task involves exploring existing research, selecting promising approaches, and implementing a small version of your findings. This take -home task gives you the opportunity to demonstrate your strengths in an open -ended way. If we like your submission, we'll invite you for a technical interview where you'll present and discuss your work in detail. Instructions Part 1: Research & Selection 1. Review the following GitHub repository, which contains a curated collection of papers and resources on audio deepfake detection. o https://github.com/media -sec-lab/Audio -Deepfake -Detection 2. Identify 3 models/ Forgery Detection approaches that", "you believe show the most promise for our use case: o Detecting AI -generated human speech o Potential for real -time or near real -time detection o Analysis of real conversations 3. For each identified approach, provide a brief summary that includes: o Key technical innovation o Reported performance metrics o Why you find this approach promising for our specific needs", "o Potential limitations or challenges You are welcome to keep this section concise (point -form and short blurb etc.) the key is the content and your thought process behind selection of models Part 2: Implementation 1. Select one of your three identified approaches to implement. o If you've done previous work in this area, feel free to showcase it o However, be sure to compare your implementation with the three approaches you selected and highlight the technical differences 2. Find and use existing code for this approach if available (this is fully acceptable and encouraged). o Preferably in a Jupyter", "notebook or similar format 3. Select an appropriate dataset. Example: o ASVspoof 5 You are encouraged to find your own dataset as well! o The shared repo contains additional audio deepfake datasets: https://github.com/media -sec-lab/Audio -Deepfake -Detection?tab=readme -ov-file#datasets 4. Perform light re -training/fine -tuning using the dataset. o This step evaluates your ability to work with large datasets and implement model training o Actual model performance is not a primary evaluation factor - our focus is on your approach and reasoning Part 3: Documentation & Analysis 1. Document your implementation process, including: o Any challenges encountered o How you addressed these", "challenges o Assumptions made 2. Include an analysis section that addresses:", "o Why you selected this particular model for implementation o How the model works (high -level technical explanation) o Performance results on your chosen dataset o Observed strengths and weaknesses o Suggestions for future improvements 3. Reflection questions to address: 1. What were the most significant challenges in implementing this model? 2. How might this approach perform in real -world conditions vs. research datasets? 3. What additional data or resources would improve performance? 4. How would you approach deploying this model in a production environment? Evaluation Criteria Your submission will be evaluated based on: \u2022 Research quality (25%): Thoughtfulness in", "model selection and analysis \u2022 Technical implementation (35%): Correctness and quality of implementation o Note: model performance is not critical to evaluation \u2022 Critical thinking (20%): Depth of analysis and insights \u2022 Documentation clarity (20%): Organization and clarity of explanations Submission Guidelines 1. Format : o Submit your solution as a public GitHub repository o Submit your GitHub repository URL as plain text in your email \u25aa e.g., github.com/yourusername/repository -name \u25aa Do not send a clickable hyperlink. 2. Requirements : o Include clear setup instructions o Document any dependencies", "o Ensure reproducibility (provide access to data or clear instructions for obtaining \nit) \n3. Deadline : Please complete and submit this assessment within 5 business days  of \nreceiving it.  \n \nGood luck! We look forward to reviewing your submission.", "Momenta - Audio Deepfake Detection Take -Home Assessment Welcome! Thank you for your interest in joining the Momenta team! This take -home assessment is designed to evaluate your approach to researching, implementing, and documenting audio deepfake detection solutions. We value your time and have structured this assessmen t to be completed within approximately 3 -5 hours. Assessment Overview Audio deepfakes pose an emerging threat to digital trust. At Momenta, we're developing robust detection systems to identify manipulated audio content across various contexts. Our interview process strays from whiteboard puzzles or DSA questions - we fundam entally believe in testing for", "skills that we expect will be needed. Your task involves exploring existing research, selecting promising approaches, and implementing a small version of your findings. This take -home task gives you the opportunity to demonstrate your strengths in an open -ended way. If we like your submission, we'll invite you for a technical interview where you'll present and discuss your work in detail. Instructions Part 1: Research & Selection 1. Review the following GitHub repository, which contains a curated collection of papers and resources on audio deepfake detection. o https://github.com/media -sec-lab/Audio -Deepfake -Detection 2. Identify 3 models/ Forgery Detection approaches that", "you believe show the most promise for our use case: o Detecting AI -generated human speech o Potential for real -time or near real -time detection o Analysis of real conversations 3. For each identified approach, provide a brief summary that includes: o Key technical innovation o Reported performance metrics o Why you find this approach promising for our specific needs", "o Potential limitations or challenges You are welcome to keep this section concise (point -form and short blurb etc.) the key is the content and your thought process behind selection of models Part 2: Implementation 1. Select one of your three identified approaches to implement. o If you've done previous work in this area, feel free to showcase it o However, be sure to compare your implementation with the three approaches you selected and highlight the technical differences 2. Find and use existing code for this approach if available (this is fully acceptable and encouraged). o Preferably in a Jupyter", "notebook or similar format 3. Select an appropriate dataset. Example: o ASVspoof 5 You are encouraged to find your own dataset as well! o The shared repo contains additional audio deepfake datasets: https://github.com/media -sec-lab/Audio -Deepfake -Detection?tab=readme -ov-file#datasets 4. Perform light re -training/fine -tuning using the dataset. o This step evaluates your ability to work with large datasets and implement model training o Actual model performance is not a primary evaluation factor - our focus is on your approach and reasoning Part 3: Documentation & Analysis 1. Document your implementation process, including: o Any challenges encountered o How you addressed these", "challenges o Assumptions made 2. Include an analysis section that addresses:", "o Why you selected this particular model for implementation o How the model works (high -level technical explanation) o Performance results on your chosen dataset o Observed strengths and weaknesses o Suggestions for future improvements 3. Reflection questions to address: 1. What were the most significant challenges in implementing this model? 2. How might this approach perform in real -world conditions vs. research datasets? 3. What additional data or resources would improve performance? 4. How would you approach deploying this model in a production environment? Evaluation Criteria Your submission will be evaluated based on: \u2022 Research quality (25%): Thoughtfulness in", "model selection and analysis \u2022 Technical implementation (35%): Correctness and quality of implementation o Note: model performance is not critical to evaluation \u2022 Critical thinking (20%): Depth of analysis and insights \u2022 Documentation clarity (20%): Organization and clarity of explanations Submission Guidelines 1. Format : o Submit your solution as a public GitHub repository o Submit your GitHub repository URL as plain text in your email \u25aa e.g., github.com/yourusername/repository -name \u25aa Do not send a clickable hyperlink. 2. Requirements : o Include clear setup instructions o Document any dependencies", "o Ensure reproducibility (provide access to data or clear instructions for obtaining \nit) \n3. Deadline : Please complete and submit this assessment within 5 business days  of \nreceiving it.  \n \nGood luck! We look forward to reviewing your submission."]